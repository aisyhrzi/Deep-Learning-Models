{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbOgXw9pm44e8Tlf4tK1E4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aisyhrzi/DeepLearning/blob/main/CB2_ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ANN USING RELU\n",
        "# Importing libraries\n",
        "import numpy as np\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "# Loading the dataset\n",
        "(X_train, y_train),(X_test, y_test)=fashion_mnist.load_data()\n",
        "\n",
        "# Normalizing the images\n",
        "X_train=X_train/255\n",
        "X_test=X_test/255\n",
        "\n",
        "# Reshaping the data\n",
        "X_train.shape\n",
        "X_train=X_train.reshape(-1,28*28)\n",
        "X_train.shape\n",
        "X_test=X_test.reshape(-1,28*28)\n",
        "X_test.shape\n",
        "\n",
        "# 1. Defining the model\n",
        "model=tf.keras.models.Sequential()\n",
        "\n",
        "# 2. Adding a first fully connected hidden layer\n",
        "model.add(tf.keras.layers.Dense(units=128, activation='relu',input_shape=(784,)))\n",
        "# number of units/neurons: 128\n",
        "# activation function: ReLU\n",
        "# input_shape: (784,)\n",
        "\n",
        "# 3. Adding second layer with dropout\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "# 4. Adding the output layer\n",
        "model.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n",
        "# units: number of classes (10 in Fashion MNIST dataset)\n",
        "# activation: softmax\n",
        "\n",
        "# 5. Compiling the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
        "# Optimizer: Adam\n",
        "# Loss: Sparse softmax (categorical) crossentropy\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 6. Training the model\n",
        "model.fit(X_train, y_train, epochs=10)\n",
        "\n",
        "# 7. Model evaluation and prediction\n",
        "test_loss, test_accuracy=model.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy: {}\".format(test_accuracy))\n",
        "\n"
      ],
      "metadata": {
        "id": "qDU7DBDRpmkd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00ce3fd2-9bb1-4551-ed12-a4e96ef19b09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               100480    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101770 (397.54 KB)\n",
            "Trainable params: 101770 (397.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 13s 6ms/step - loss: 0.5291 - sparse_categorical_accuracy: 0.8123\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4019 - sparse_categorical_accuracy: 0.8541\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3663 - sparse_categorical_accuracy: 0.8663\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3452 - sparse_categorical_accuracy: 0.8734\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3281 - sparse_categorical_accuracy: 0.8791\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3169 - sparse_categorical_accuracy: 0.8819\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3074 - sparse_categorical_accuracy: 0.8871\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2968 - sparse_categorical_accuracy: 0.8893\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2930 - sparse_categorical_accuracy: 0.8909\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2835 - sparse_categorical_accuracy: 0.8937\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3385 - sparse_categorical_accuracy: 0.8790\n",
            "Test accuracy: 0.8790000081062317\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ANN USING SOFTMAX\n",
        "# Importing libraries\n",
        "import numpy as np\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "# Loading the dataset\n",
        "(X_train, y_train),(X_test, y_test)=fashion_mnist.load_data()\n",
        "\n",
        "# Normalizing the images\n",
        "X_train=X_train/255\n",
        "X_test=X_test/255\n",
        "\n",
        "# Reshaping the data\n",
        "X_train.shape\n",
        "X_train=X_train.reshape(-1,28*28)\n",
        "X_train.shape\n",
        "X_test=X_test.reshape(-1,28*28)\n",
        "X_test.shape\n",
        "\n",
        "# 1. Defining the model\n",
        "model=tf.keras.models.Sequential()\n",
        "\n",
        "# 2. Adding a first fully connected hidden layer\n",
        "model.add(tf.keras.layers.Dense(units=128, activation='softmax',input_shape=(784,)))\n",
        "# number of units/neurons: 128\n",
        "# activation function: ReLU\n",
        "# input_shape: (784,)\n",
        "\n",
        "# 3. Adding second layer with dropout\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "# 4. Adding the output layer\n",
        "model.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n",
        "# units: number of classes (10 in Fashion MNIST dataset)\n",
        "# activation: softmax\n",
        "\n",
        "# 5. Compiling the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
        "# Optimizer: Adam\n",
        "# Loss: Sparse softmax (categorical) crossentropy\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 6. Training the model\n",
        "model.fit(X_train, y_train, epochs=10)\n",
        "\n",
        "# 7. Model evaluation and prediction\n",
        "test_loss, test_accuracy=model.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy: {}\".format(test_accuracy))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeZFA1JYvCBl",
        "outputId": "0afbf276-9c68-4af4-feea-86556e59eb2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 128)               100480    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101770 (397.54 KB)\n",
            "Trainable params: 101770 (397.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 1.5113 - sparse_categorical_accuracy: 0.5286\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 1.0906 - sparse_categorical_accuracy: 0.5774\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 1.0044 - sparse_categorical_accuracy: 0.6024\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.9659 - sparse_categorical_accuracy: 0.6223\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.8975 - sparse_categorical_accuracy: 0.6599\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.8331 - sparse_categorical_accuracy: 0.6872\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.7939 - sparse_categorical_accuracy: 0.7007\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7589 - sparse_categorical_accuracy: 0.7251\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.7362 - sparse_categorical_accuracy: 0.7278\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7168 - sparse_categorical_accuracy: 0.7323\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.4998 - sparse_categorical_accuracy: 0.8344\n",
            "Test accuracy: 0.8343999981880188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ANN USING ELU\n",
        "# Importing libraries\n",
        "import numpy as np\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "# Loading the dataset\n",
        "(X_train, y_train),(X_test, y_test)=fashion_mnist.load_data()\n",
        "\n",
        "# Normalizing the images\n",
        "X_train=X_train/255\n",
        "X_test=X_test/255\n",
        "\n",
        "# Reshaping the data\n",
        "X_train.shape\n",
        "X_train=X_train.reshape(-1,28*28)\n",
        "X_train.shape\n",
        "X_test=X_test.reshape(-1,28*28)\n",
        "X_test.shape\n",
        "\n",
        "# 1. Defining the model\n",
        "model=tf.keras.models.Sequential()\n",
        "\n",
        "# 2. Adding a first fully connected hidden layer\n",
        "model.add(tf.keras.layers.Dense(units=128, activation='elu',input_shape=(784,)))\n",
        "# number of units/neurons: 128\n",
        "# activation function: ReLU\n",
        "# input_shape: (784,)\n",
        "\n",
        "# 3. Adding second layer with dropout\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "# 4. Adding the output layer\n",
        "model.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n",
        "# units: number of classes (10 in Fashion MNIST dataset)\n",
        "# activation: softmax\n",
        "\n",
        "# 5. Compiling the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
        "# Optimizer: Adam\n",
        "# Loss: Sparse softmax (categorical) crossentropy\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 6. Training the model\n",
        "model.fit(X_train, y_train, epochs=10)\n",
        "\n",
        "# 7. Model evaluation and prediction\n",
        "test_loss, test_accuracy=model.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy: {}\".format(test_accuracy))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25_iPwBBwICF",
        "outputId": "f07748e3-5fdb-4487-adf4-1251d820b0a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_10 (Dense)            (None, 128)               100480    \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101770 (397.54 KB)\n",
            "Trainable params: 101770 (397.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.5240 - sparse_categorical_accuracy: 0.8133\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4135 - sparse_categorical_accuracy: 0.8495\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3812 - sparse_categorical_accuracy: 0.8615\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3556 - sparse_categorical_accuracy: 0.8694\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3401 - sparse_categorical_accuracy: 0.8761\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3279 - sparse_categorical_accuracy: 0.8785\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3170 - sparse_categorical_accuracy: 0.8819\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3076 - sparse_categorical_accuracy: 0.8865\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2999 - sparse_categorical_accuracy: 0.8879\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2945 - sparse_categorical_accuracy: 0.8903\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3275 - sparse_categorical_accuracy: 0.8810\n",
            "Test accuracy: 0.8809999823570251\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ANN USING PRELU\n",
        "# Importing libraries\n",
        "import numpy as np\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "# Loading the dataset\n",
        "(X_train, y_train),(X_test, y_test)=fashion_mnist.load_data()\n",
        "\n",
        "# Normalizing the images\n",
        "X_train=X_train/255\n",
        "X_test=X_test/255\n",
        "\n",
        "# Reshaping the data\n",
        "X_train.shape\n",
        "X_train=X_train.reshape(-1,28*28)\n",
        "X_train.shape\n",
        "X_test=X_test.reshape(-1,28*28)\n",
        "X_test.shape\n",
        "\n",
        "# 1. Defining the model\n",
        "model=tf.keras.models.Sequential()\n",
        "\n",
        "# 2. Adding a first fully connected hidden layer\n",
        "model.add(tf.keras.layers.Dense(units=128, activation='PReLU',input_shape=(784,)))\n",
        "# number of units/neurons: 128\n",
        "# activation function: ReLU\n",
        "# input_shape: (784,)\n",
        "\n",
        "# 3. Adding second layer with dropout\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "# 4. Adding the output layer\n",
        "model.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n",
        "# units: number of classes (10 in Fashion MNIST dataset)\n",
        "# activation: softmax\n",
        "\n",
        "# 5. Compiling the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
        "# Optimizer: Adam\n",
        "# Loss: Sparse softmax (categorical) crossentropy\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 6. Training the model\n",
        "model.fit(X_train, y_train, epochs=10)\n",
        "\n",
        "# 7. Model evaluation and prediction\n",
        "test_loss, test_accuracy=model.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy: {}\".format(test_accuracy))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTiGdLhYwgpW",
        "outputId": "3fd74013-d2c9-4a70-bc43-fc47a3f14e24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_14 (Dense)            (None, 128)               100608    \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101898 (398.04 KB)\n",
            "Trainable params: 101898 (398.04 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.5286 - sparse_categorical_accuracy: 0.8130\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4013 - sparse_categorical_accuracy: 0.8562\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3652 - sparse_categorical_accuracy: 0.8668\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3464 - sparse_categorical_accuracy: 0.8737\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3292 - sparse_categorical_accuracy: 0.8803\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3181 - sparse_categorical_accuracy: 0.8824\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3083 - sparse_categorical_accuracy: 0.8853\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2989 - sparse_categorical_accuracy: 0.8894\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2910 - sparse_categorical_accuracy: 0.8928\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2853 - sparse_categorical_accuracy: 0.8932\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3306 - sparse_categorical_accuracy: 0.8839\n",
            "Test accuracy: 0.883899986743927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ANN USING TANH\n",
        "# Importing libraries\n",
        "import numpy as np\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "# Loading the dataset\n",
        "(X_train, y_train),(X_test, y_test)=fashion_mnist.load_data()\n",
        "\n",
        "# Normalizing the images\n",
        "X_train=X_train/255\n",
        "X_test=X_test/255\n",
        "\n",
        "# Reshaping the data\n",
        "X_train.shape\n",
        "X_train=X_train.reshape(-1,28*28)\n",
        "X_train.shape\n",
        "X_test=X_test.reshape(-1,28*28)\n",
        "X_test.shape\n",
        "\n",
        "# 1. Defining the model\n",
        "model=tf.keras.models.Sequential()\n",
        "\n",
        "# 2. Adding a first fully connected hidden layer\n",
        "model.add(tf.keras.layers.Dense(units=128, activation='tanh',input_shape=(784,)))\n",
        "# number of units/neurons: 128\n",
        "# activation function: ReLU\n",
        "# input_shape: (784,)\n",
        "\n",
        "# 3. Adding second layer with dropout\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "# 4. Adding the output layer\n",
        "model.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n",
        "# units: number of classes (10 in Fashion MNIST dataset)\n",
        "# activation: softmax\n",
        "\n",
        "# 5. Compiling the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
        "# Optimizer: Adam\n",
        "# Loss: Sparse softmax (categorical) crossentropy\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 6. Training the model\n",
        "model.fit(X_train, y_train, epochs=10)\n",
        "\n",
        "# 7. Model evaluation and prediction\n",
        "test_loss, test_accuracy=model.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy: {}\".format(test_accuracy))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAoder7UzA2f",
        "outputId": "624e7ebb-ff73-4617-f23c-e32437fb0009"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_16 (Dense)            (None, 128)               100480    \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101770 (397.54 KB)\n",
            "Trainable params: 101770 (397.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5187 - sparse_categorical_accuracy: 0.8153\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4132 - sparse_categorical_accuracy: 0.8503\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3848 - sparse_categorical_accuracy: 0.8610\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3654 - sparse_categorical_accuracy: 0.8675\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3510 - sparse_categorical_accuracy: 0.8719\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3419 - sparse_categorical_accuracy: 0.8745\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3303 - sparse_categorical_accuracy: 0.8795\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3239 - sparse_categorical_accuracy: 0.8817\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3165 - sparse_categorical_accuracy: 0.8836\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3110 - sparse_categorical_accuracy: 0.8861\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3463 - sparse_categorical_accuracy: 0.8763\n",
            "Test accuracy: 0.8762999773025513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ANN USING LeakyRelu\n",
        "# Importing libraries\n",
        "import numpy as np\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "# Loading the dataset\n",
        "(X_train, y_train),(X_test, y_test)=fashion_mnist.load_data()\n",
        "\n",
        "# Normalizing the images\n",
        "X_train=X_train/255\n",
        "X_test=X_test/255\n",
        "\n",
        "# Reshaping the data\n",
        "X_train.shape\n",
        "X_train=X_train.reshape(-1,28*28)\n",
        "X_train.shape\n",
        "X_test=X_test.reshape(-1,28*28)\n",
        "X_test.shape\n",
        "\n",
        "# 1. Defining the model\n",
        "model=tf.keras.models.Sequential()\n",
        "\n",
        "# 2. Adding a first fully connected hidden layer\n",
        "model.add(tf.keras.layers.Dense(units=128, activation='leaky_relu',input_shape=(784,)))\n",
        "# number of units/neurons: 128\n",
        "# activation function: ReLU\n",
        "# input_shape: (784,)\n",
        "\n",
        "# 3. Adding second layer with dropout\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "# 4. Adding the output layer\n",
        "model.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n",
        "# units: number of classes (10 in Fashion MNIST dataset)\n",
        "# activation: softmax\n",
        "\n",
        "# 5. Compiling the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
        "# Optimizer: Adam\n",
        "# Loss: Sparse softmax (categorical) crossentropy\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 6. Training the model\n",
        "model.fit(X_train, y_train, epochs=10)\n",
        "\n",
        "# 7. Model evaluation and prediction\n",
        "test_loss, test_accuracy=model.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy: {}\".format(test_accuracy))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gscXQuUfzp6e",
        "outputId": "38599d14-041e-4703-ead4-0cc334c338f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_21 (Dense)            (None, 128)               100480    \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101770 (397.54 KB)\n",
            "Trainable params: 101770 (397.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5307 - sparse_categorical_accuracy: 0.8145\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4140 - sparse_categorical_accuracy: 0.8515\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3862 - sparse_categorical_accuracy: 0.8601\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3659 - sparse_categorical_accuracy: 0.8672\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3558 - sparse_categorical_accuracy: 0.8691\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3411 - sparse_categorical_accuracy: 0.8754\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3338 - sparse_categorical_accuracy: 0.8766\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3249 - sparse_categorical_accuracy: 0.8807\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3237 - sparse_categorical_accuracy: 0.8806\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3147 - sparse_categorical_accuracy: 0.8844\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3679 - sparse_categorical_accuracy: 0.8700\n",
            "Test accuracy: 0.8700000047683716\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ANN USING sigmoid\n",
        "# Importing libraries\n",
        "import numpy as np\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "# Loading the dataset\n",
        "(X_train, y_train),(X_test, y_test)=fashion_mnist.load_data()\n",
        "\n",
        "# Normalizing the images\n",
        "X_train=X_train/255\n",
        "X_test=X_test/255\n",
        "\n",
        "# Reshaping the data\n",
        "X_train.shape\n",
        "X_train=X_train.reshape(-1,28*28)\n",
        "X_train.shape\n",
        "X_test=X_test.reshape(-1,28*28)\n",
        "X_test.shape\n",
        "\n",
        "# 1. Defining the model\n",
        "model=tf.keras.models.Sequential()\n",
        "\n",
        "# 2. Adding a first fully connected hidden layer\n",
        "model.add(tf.keras.layers.Dense(units=128, activation='sigmoid',input_shape=(784,)))\n",
        "# number of units/neurons: 128\n",
        "# activation function: ReLU\n",
        "# input_shape: (784,)\n",
        "\n",
        "# 3. Adding second layer with dropout\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "# 4. Adding the output layer\n",
        "model.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n",
        "# units: number of classes (10 in Fashion MNIST dataset)\n",
        "# activation: softmax\n",
        "\n",
        "# 5. Compiling the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
        "# Optimizer: Adam\n",
        "# Loss: Sparse softmax (categorical) crossentropy\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 6. Training the model\n",
        "model.fit(X_train, y_train, epochs=10)\n",
        "\n",
        "# 7. Model evaluation and prediction\n",
        "test_loss, test_accuracy=model.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy: {}\".format(test_accuracy))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LtF-qNUzKl8",
        "outputId": "54ebdfd9-d271-4b1a-ca95-5e26136dc434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_18 (Dense)            (None, 128)               100480    \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101770 (397.54 KB)\n",
            "Trainable params: 101770 (397.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 0.5782 - sparse_categorical_accuracy: 0.7991\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4179 - sparse_categorical_accuracy: 0.8488\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3826 - sparse_categorical_accuracy: 0.8619\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3607 - sparse_categorical_accuracy: 0.8683\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3417 - sparse_categorical_accuracy: 0.8760\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3274 - sparse_categorical_accuracy: 0.8806\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.3178 - sparse_categorical_accuracy: 0.8835\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3074 - sparse_categorical_accuracy: 0.8870\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2986 - sparse_categorical_accuracy: 0.8905\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2904 - sparse_categorical_accuracy: 0.8923\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3346 - sparse_categorical_accuracy: 0.8794\n",
            "Test accuracy: 0.8794000148773193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ANN USING LeakyRelu and RMSprop\n",
        "\n",
        "# Importing libraries\n",
        "import numpy as np\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "# Loading the dataset\n",
        "(X_train, y_train),(X_test, y_test)=fashion_mnist.load_data()\n",
        "\n",
        "# Normalizing the images\n",
        "X_train=X_train/255\n",
        "X_test=X_test/255\n",
        "\n",
        "# Reshaping the data\n",
        "X_train.shape\n",
        "X_train=X_train.reshape(-1,28*28)\n",
        "X_train.shape\n",
        "X_test=X_test.reshape(-1,28*28)\n",
        "X_test.shape\n",
        "\n",
        "# 1. Defining the model\n",
        "model=tf.keras.models.Sequential()\n",
        "\n",
        "# 2. Adding a first fully connected hidden layer\n",
        "model.add(tf.keras.layers.Dense(units=128, activation='leaky_relu',input_shape=(784,)))\n",
        "# number of units/neurons: 128\n",
        "# activation function: ReLU\n",
        "# input_shape: (784,)\n",
        "\n",
        "# 3. Adding second layer with dropout\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "# 4. Adding the output layer\n",
        "model.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n",
        "# units: number of classes (10 in Fashion MNIST dataset)\n",
        "# activation: softmax\n",
        "\n",
        "# 5. Compiling the model\n",
        "model.compile(optimizer='RMSProp', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
        "# Optimizer: Adam\n",
        "# Loss: Sparse softmax (categorical) crossentropy\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 6. Training the model\n",
        "model.fit(X_train, y_train, epochs=10)\n",
        "\n",
        "# 7. Model evaluation and prediction\n",
        "test_loss, test_accuracy=model.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy: {}\".format(test_accuracy))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIBijzMO1lvI",
        "outputId": "f8bd71d7-1bec-4354-de7f-85f338a947e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_23 (Dense)            (None, 128)               100480    \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101770 (397.54 KB)\n",
            "Trainable params: 101770 (397.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.5448 - sparse_categorical_accuracy: 0.8081\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4250 - sparse_categorical_accuracy: 0.8488\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3983 - sparse_categorical_accuracy: 0.8580\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3805 - sparse_categorical_accuracy: 0.8649\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3672 - sparse_categorical_accuracy: 0.8691\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3590 - sparse_categorical_accuracy: 0.8721\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3530 - sparse_categorical_accuracy: 0.8752\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3477 - sparse_categorical_accuracy: 0.8763\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.3410 - sparse_categorical_accuracy: 0.8782\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3341 - sparse_categorical_accuracy: 0.8802\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3764 - sparse_categorical_accuracy: 0.8616\n",
            "Test accuracy: 0.8615999817848206\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ANN USING LeakyRelu and AdaGrad\n",
        "\n",
        "# Importing libraries\n",
        "import numpy as np\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "# Loading the dataset\n",
        "(X_train, y_train),(X_test, y_test)=fashion_mnist.load_data()\n",
        "\n",
        "# Normalizing the images\n",
        "X_train=X_train/255\n",
        "X_test=X_test/255\n",
        "\n",
        "# Reshaping the data\n",
        "X_train.shape\n",
        "X_train=X_train.reshape(-1,28*28)\n",
        "X_train.shape\n",
        "X_test=X_test.reshape(-1,28*28)\n",
        "X_test.shape\n",
        "\n",
        "# 1. Defining the model\n",
        "model=tf.keras.models.Sequential()\n",
        "\n",
        "# 2. Adding a first fully connected hidden layer\n",
        "model.add(tf.keras.layers.Dense(units=128, activation='leaky_relu',input_shape=(784,)))\n",
        "# number of units/neurons: 128\n",
        "# activation function: leaky-ReLU\n",
        "# input_shape: (784,)\n",
        "\n",
        "# 3. Adding second layer with dropout\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "# 4. Adding the output layer\n",
        "model.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n",
        "# units: number of classes (10 in Fashion MNIST dataset)\n",
        "# activation: softmax\n",
        "\n",
        "# 5. Compiling the model\n",
        "model.compile(optimizer='Adagrad', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
        "# Optimizer: adagrad\n",
        "# Loss: Sparse softmax (categorical) crossentropy\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 6. Training the model\n",
        "model.fit(X_train, y_train, epochs=10)\n",
        "\n",
        "# 7. Model evaluation and prediction\n",
        "test_loss, test_accuracy=model.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy: {}\".format(test_accuracy))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-pWmEyX3G-M",
        "outputId": "5a2d863c-efa1-42dc-f140-1f4b5246fa01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_25 (Dense)            (None, 128)               100480    \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101770 (397.54 KB)\n",
            "Trainable params: 101770 (397.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 1.1340 - sparse_categorical_accuracy: 0.6299\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.7879 - sparse_categorical_accuracy: 0.7321\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7068 - sparse_categorical_accuracy: 0.7622\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.6625 - sparse_categorical_accuracy: 0.7788\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6347 - sparse_categorical_accuracy: 0.7873\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.6112 - sparse_categorical_accuracy: 0.7955\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5951 - sparse_categorical_accuracy: 0.8016\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5817 - sparse_categorical_accuracy: 0.8046\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.5717 - sparse_categorical_accuracy: 0.8076\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5607 - sparse_categorical_accuracy: 0.8128\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.5521 - sparse_categorical_accuracy: 0.8127\n",
            "Test accuracy: 0.8126999735832214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ANN USING LeakyRelu and Adadelta\n",
        "\n",
        "# Importing libraries\n",
        "import numpy as np\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "# Loading the dataset\n",
        "(X_train, y_train),(X_test, y_test)=fashion_mnist.load_data()\n",
        "\n",
        "# Normalizing the images\n",
        "X_train=X_train/255\n",
        "X_test=X_test/255\n",
        "\n",
        "# Reshaping the data\n",
        "X_train.shape\n",
        "X_train=X_train.reshape(-1,28*28)\n",
        "X_train.shape\n",
        "X_test=X_test.reshape(-1,28*28)\n",
        "X_test.shape\n",
        "\n",
        "# 1. Defining the model\n",
        "model=tf.keras.models.Sequential()\n",
        "\n",
        "# 2. Adding a first fully connected hidden layer\n",
        "model.add(tf.keras.layers.Dense(units=128, activation='leaky_relu',input_shape=(784,)))\n",
        "# number of units/neurons: 128\n",
        "# activation function: leaky-ReLU\n",
        "# input_shape: (784,)\n",
        "\n",
        "# 3. Adding second layer with dropout\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "# 4. Adding the output layer\n",
        "model.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n",
        "# units: number of classes (10 in Fashion MNIST dataset)\n",
        "# activation: softmax\n",
        "\n",
        "# 5. Compiling the model\n",
        "model.compile(optimizer='Adadelta', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
        "# Optimizer: adagrad\n",
        "# Loss: Sparse softmax (categorical) crossentropy\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 6. Training the model\n",
        "model.fit(X_train, y_train, epochs=10)\n",
        "\n",
        "# 7. Model evaluation and prediction\n",
        "test_loss, test_accuracy=model.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy: {}\".format(test_accuracy))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVEU213u3xoB",
        "outputId": "1c46f797-fdee-4ede-d579-2fdf9d8ef761"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_27 (Dense)            (None, 128)               100480    \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101770 (397.54 KB)\n",
            "Trainable params: 101770 (397.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 2.2900 - sparse_categorical_accuracy: 0.1678\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 1.8475 - sparse_categorical_accuracy: 0.3839\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 1.5926 - sparse_categorical_accuracy: 0.4999\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 1.4179 - sparse_categorical_accuracy: 0.5574\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 1.2927 - sparse_categorical_accuracy: 0.5902\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 1.2000 - sparse_categorical_accuracy: 0.6131\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 1.1322 - sparse_categorical_accuracy: 0.6284\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 1.0763 - sparse_categorical_accuracy: 0.6423\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 1.0320 - sparse_categorical_accuracy: 0.6505\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.9964 - sparse_categorical_accuracy: 0.6611\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.9473 - sparse_categorical_accuracy: 0.6798\n",
            "Test accuracy: 0.6797999739646912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ANN USING LeakyRelu and adamax\n",
        "\n",
        "# Importing libraries\n",
        "import numpy as np\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "# Loading the dataset\n",
        "(X_train, y_train),(X_test, y_test)=fashion_mnist.load_data()\n",
        "\n",
        "# Normalizing the images\n",
        "X_train=X_train/255\n",
        "X_test=X_test/255\n",
        "\n",
        "# Reshaping the data\n",
        "X_train.shape\n",
        "X_train=X_train.reshape(-1,28*28)\n",
        "X_train.shape\n",
        "X_test=X_test.reshape(-1,28*28)\n",
        "X_test.shape\n",
        "\n",
        "# 1. Defining the model\n",
        "model=tf.keras.models.Sequential()\n",
        "\n",
        "# 2. Adding a first fully connected hidden layer\n",
        "model.add(tf.keras.layers.Dense(units=128, activation='leaky_relu',input_shape=(784,)))\n",
        "# number of units/neurons: 128\n",
        "# activation function: leaky-ReLU\n",
        "# input_shape: (784,)\n",
        "\n",
        "# 3. Adding second layer with dropout\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "# 4. Adding the output layer\n",
        "model.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n",
        "# units: number of classes (10 in Fashion MNIST dataset)\n",
        "# activation: softmax\n",
        "\n",
        "# 5. Compiling the model\n",
        "model.compile(optimizer='Adamax', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
        "# Optimizer: adagrad\n",
        "# Loss: Sparse softmax (categorical) crossentropy\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 6. Training the model\n",
        "model.fit(X_train, y_train, epochs=10)\n",
        "\n",
        "# 7. Model evaluation and prediction\n",
        "test_loss, test_accuracy=model.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy: {}\".format(test_accuracy))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BssN291-4fny",
        "outputId": "05afd39f-c509-44de-a609-10bb4afcdf09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_29 (Dense)            (None, 128)               100480    \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101770 (397.54 KB)\n",
            "Trainable params: 101770 (397.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.5972 - sparse_categorical_accuracy: 0.7950\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4496 - sparse_categorical_accuracy: 0.8426\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4088 - sparse_categorical_accuracy: 0.8554\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3872 - sparse_categorical_accuracy: 0.8630\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3730 - sparse_categorical_accuracy: 0.8670\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3597 - sparse_categorical_accuracy: 0.8723\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3502 - sparse_categorical_accuracy: 0.8762\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3420 - sparse_categorical_accuracy: 0.8781\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3356 - sparse_categorical_accuracy: 0.8798\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3294 - sparse_categorical_accuracy: 0.8813\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3728 - sparse_categorical_accuracy: 0.8617\n",
            "Test accuracy: 0.8616999983787537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ANN USING LeakyRelu and nadam\n",
        "\n",
        "# Importing libraries\n",
        "import numpy as np\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "# Loading the dataset\n",
        "(X_train, y_train),(X_test, y_test)=fashion_mnist.load_data()\n",
        "\n",
        "# Normalizing the images\n",
        "X_train=X_train/255\n",
        "X_test=X_test/255\n",
        "\n",
        "# Reshaping the data\n",
        "X_train.shape\n",
        "X_train=X_train.reshape(-1,28*28)\n",
        "X_train.shape\n",
        "X_test=X_test.reshape(-1,28*28)\n",
        "X_test.shape\n",
        "\n",
        "# 1. Defining the model\n",
        "model=tf.keras.models.Sequential()\n",
        "\n",
        "# 2. Adding a first fully connected hidden layer\n",
        "model.add(tf.keras.layers.Dense(units=128, activation='leaky_relu',input_shape=(784,)))\n",
        "# number of units/neurons: 128\n",
        "# activation function: leaky-ReLU\n",
        "# input_shape: (784,)\n",
        "\n",
        "# 3. Adding second layer with dropout\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "# 4. Adding the output layer\n",
        "model.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n",
        "# units: number of classes (10 in Fashion MNIST dataset)\n",
        "# activation: softmax\n",
        "\n",
        "# 5. Compiling the model\n",
        "model.compile(optimizer='Nadam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
        "# Optimizer: adagrad\n",
        "# Loss: Sparse softmax (categorical) crossentropy\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 6. Training the model\n",
        "model.fit(X_train, y_train, epochs=10)\n",
        "\n",
        "# 7. Model evaluation and prediction\n",
        "test_loss, test_accuracy=model.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy: {}\".format(test_accuracy))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gZ7ewHT4leV",
        "outputId": "0c5b3285-3875-41c3-c5fe-12e9f4bab102"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_31 (Dense)            (None, 128)               100480    \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101770 (397.54 KB)\n",
            "Trainable params: 101770 (397.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.5200 - sparse_categorical_accuracy: 0.8167\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4080 - sparse_categorical_accuracy: 0.8528\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3769 - sparse_categorical_accuracy: 0.8632\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3594 - sparse_categorical_accuracy: 0.8689\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3503 - sparse_categorical_accuracy: 0.8724\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3389 - sparse_categorical_accuracy: 0.8768\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3297 - sparse_categorical_accuracy: 0.8792\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3238 - sparse_categorical_accuracy: 0.8820\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3162 - sparse_categorical_accuracy: 0.8835\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3109 - sparse_categorical_accuracy: 0.8853\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3579 - sparse_categorical_accuracy: 0.8731\n",
            "Test accuracy: 0.8730999827384949\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zClfuOK-5idk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ANN USING LeakyRelu and SGD\n",
        "\n",
        "# Importing libraries\n",
        "import numpy as np\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "# Loading the dataset\n",
        "(X_train, y_train),(X_test, y_test)=fashion_mnist.load_data()\n",
        "\n",
        "# Normalizing the images\n",
        "X_train=X_train/255\n",
        "X_test=X_test/255\n",
        "\n",
        "# Reshaping the data\n",
        "X_train.shape\n",
        "X_train=X_train.reshape(-1,28*28)\n",
        "X_train.shape\n",
        "X_test=X_test.reshape(-1,28*28)\n",
        "X_test.shape\n",
        "\n",
        "# 1. Defining the model\n",
        "model=tf.keras.models.Sequential()\n",
        "\n",
        "# 2. Adding a first fully connected hidden layer\n",
        "model.add(tf.keras.layers.Dense(units=128, activation='leaky_relu',input_shape=(784,)))\n",
        "# number of units/neurons: 128\n",
        "# activation function: leaky-ReLU\n",
        "# input_shape: (784,)\n",
        "\n",
        "# 3. Adding second layer with dropout\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "# 4. Adding the output layer\n",
        "model.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n",
        "# units: number of classes (10 in Fashion MNIST dataset)\n",
        "# activation: softmax\n",
        "\n",
        "# 5. Compiling the model\n",
        "model.compile(optimizer='SGD', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
        "# Optimizer: adagrad\n",
        "# Loss: Sparse softmax (categorical) crossentropy\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 6. Training the model\n",
        "model.fit(X_train, y_train, epochs=10)\n",
        "\n",
        "# 7. Model evaluation and prediction\n",
        "test_loss, test_accuracy=model.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy: {}\".format(test_accuracy))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JCzMyIN4qxR",
        "outputId": "3ad2a4bc-02f4-47c2-d901-334041cc57e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_33 (Dense)            (None, 128)               100480    \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101770 (397.54 KB)\n",
            "Trainable params: 101770 (397.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7922 - sparse_categorical_accuracy: 0.7382\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5504 - sparse_categorical_accuracy: 0.8127\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4961 - sparse_categorical_accuracy: 0.8295\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4668 - sparse_categorical_accuracy: 0.8387\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4436 - sparse_categorical_accuracy: 0.8459\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4319 - sparse_categorical_accuracy: 0.8485\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4173 - sparse_categorical_accuracy: 0.8545\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4092 - sparse_categorical_accuracy: 0.8568\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4001 - sparse_categorical_accuracy: 0.8588\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3924 - sparse_categorical_accuracy: 0.8617\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.4164 - sparse_categorical_accuracy: 0.8534\n",
            "Test accuracy: 0.8533999919891357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "# Load Fashion MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize the images\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# Reshape the data\n",
        "X_train = X_train.reshape(-1, 28*28)\n",
        "X_test = X_test.reshape(-1, 28*28)\n",
        "\n",
        "# Define Leaky ReLU activation function\n",
        "def leaky_relu(x):\n",
        "    return tf.nn.leaky_relu(x, alpha=0.01)\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(units=128, activation=leaky_relu, input_shape=(784,)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(units=10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model with SGD optimizer and momentum\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
        "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy: {}\".format(test_accuracy))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGJhuYrw6JJb",
        "outputId": "18b6cf33-1415-4d3d-e6f0-13a25ae98644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_37 (Dense)            (None, 128)               100480    \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101770 (397.54 KB)\n",
            "Trainable params: 101770 (397.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.5633 - sparse_categorical_accuracy: 0.7994\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4256 - sparse_categorical_accuracy: 0.8473\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3902 - sparse_categorical_accuracy: 0.8581\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3695 - sparse_categorical_accuracy: 0.8643\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3541 - sparse_categorical_accuracy: 0.8702\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3400 - sparse_categorical_accuracy: 0.8749\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3325 - sparse_categorical_accuracy: 0.8785\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3226 - sparse_categorical_accuracy: 0.8832\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3145 - sparse_categorical_accuracy: 0.8849\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3064 - sparse_categorical_accuracy: 0.8861\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3527 - sparse_categorical_accuracy: 0.8699\n",
            "Test accuracy: 0.8698999881744385\n"
          ]
        }
      ]
    }
  ]
}