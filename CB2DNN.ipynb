{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVia4zfteRp0wwokfL1nnt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aisyhrzi/DeepLearning/blob/main/CB2DNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DNN USING  RELU INPUT ACTIVATION\n"
      ],
      "metadata": {
        "id": "ltb6JJYUkMta"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "587GaWsC01-9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "656d1461-a7d6-4eb6-e412-13e5a31c7ccb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 13s 6ms/step - loss: 0.2425 - accuracy: 0.9296\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1042 - accuracy: 0.9681\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0740 - accuracy: 0.9768\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0563 - accuracy: 0.9822\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0440 - accuracy: 0.9859\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0822 - accuracy: 0.9767\n",
            "Test accuracy: 0.9767000079154968\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Define the architecture of the DNN\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(784,)),  # Input layer with 128 neurons and ReLU activation\n",
        "    Dense(64, activation='relu'),                       # Hidden layer with 64 neurons and ReLU activation\n",
        "    Dense(10, activation='softmax')                     # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',   # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
        "\n",
        "# Flatten the data\n",
        "x_train_flattened = x_train.reshape(-1, 28*28)\n",
        "x_test_flattened = x_test.reshape(-1, 28*28)\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train_flattened, y_train, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test_flattened, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DNN USING SOFTMAX INPUT ACTIVATION"
      ],
      "metadata": {
        "id": "vUVTNCNokU0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Define the architecture of the DNN\n",
        "model = Sequential([\n",
        "    Dense(128, activation='softmax', input_shape=(784,)),  # Input layer with 128 neurons and ReLU activation\n",
        "    Dense(64, activation='relu'),                       # Hidden layer with 64 neurons and ReLU activation\n",
        "    Dense(10, activation='softmax')                     # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',   # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
        "\n",
        "# Flatten the data\n",
        "x_train_flattened = x_train.reshape(-1, 28*28)\n",
        "x_test_flattened = x_test.reshape(-1, 28*28)\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train_flattened, y_train, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test_flattened, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWK6kmHtkczr",
        "outputId": "de862420-516b-4386-cbd9-cd5950325d7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4692 - accuracy: 0.8840\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2288 - accuracy: 0.9359\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2001 - accuracy: 0.9439\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1819 - accuracy: 0.9489\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1663 - accuracy: 0.9534\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1756 - accuracy: 0.9490\n",
            "Test accuracy: 0.9490000009536743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DNN - ELU\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TMNDKEr1kq5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Define the architecture of the DNN\n",
        "model = Sequential([\n",
        "    Dense(128, activation='ELU', input_shape=(784,)),  # Input layer with 128 neurons and eLU activation\n",
        "    Dense(64, activation='relu'),                       # Hidden layer with 64 neurons and ReLU activation\n",
        "    Dense(10, activation='softmax')                     # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',   # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
        "\n",
        "# Flatten the data\n",
        "x_train_flattened = x_train.reshape(-1, 28*28)\n",
        "x_test_flattened = x_test.reshape(-1, 28*28)\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train_flattened, y_train, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test_flattened, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW63puxclUUg",
        "outputId": "797f80e8-4c63-4417-9e6c-0cf58a2510ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2558 - accuracy: 0.9236\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1131 - accuracy: 0.9648\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0789 - accuracy: 0.9751\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0594 - accuracy: 0.9811\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0478 - accuracy: 0.9848\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0783 - accuracy: 0.9757\n",
            "Test accuracy: 0.9757000207901001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DNN - PRELU\n"
      ],
      "metadata": {
        "id": "a0RZvhr2myBG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Define the architecture of the DNN\n",
        "model = Sequential([\n",
        "    Dense(128, activation='PReLU', input_shape=(784,)),  # Input layer with 128 neurons and eLU activation\n",
        "    Dense(64, activation='relu'),                       # Hidden layer with 64 neurons and ReLU activation\n",
        "    Dense(10, activation='softmax')                     # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',   # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
        "\n",
        "# Flatten the data\n",
        "x_train_flattened = x_train.reshape(-1, 28*28)\n",
        "x_test_flattened = x_test.reshape(-1, 28*28)\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train_flattened, y_train, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test_flattened, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrZy5r-fmsOF",
        "outputId": "a140d225-3bd0-4c07-8001-a19b02d37fc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2412 - accuracy: 0.9293\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0965 - accuracy: 0.9702\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0671 - accuracy: 0.9785\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0516 - accuracy: 0.9838\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0413 - accuracy: 0.9870\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0859 - accuracy: 0.9743\n",
            "Test accuracy: 0.9743000268936157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DNN -TANH"
      ],
      "metadata": {
        "id": "jRBAmtKxm1lu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Define the architecture of the DNN\n",
        "model = Sequential([\n",
        "    Dense(128, activation='tanh', input_shape=(784,)),  # Input layer with 128 neurons and eLU activation\n",
        "    Dense(64, activation='relu'),                       # Hidden layer with 64 neurons and ReLU activation\n",
        "    Dense(10, activation='softmax')                     # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',   # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
        "\n",
        "# Flatten the data\n",
        "x_train_flattened = x_train.reshape(-1, 28*28)\n",
        "x_test_flattened = x_test.reshape(-1, 28*28)\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train_flattened, y_train, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test_flattened, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWkkcdQLm-k5",
        "outputId": "fbf653fe-5172-42ee-ebbc-e9560f172fd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2432 - accuracy: 0.9274\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1098 - accuracy: 0.9662\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0761 - accuracy: 0.9761\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0564 - accuracy: 0.9818\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0434 - accuracy: 0.9858\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0827 - accuracy: 0.9754\n",
            "Test accuracy: 0.9753999710083008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DNN -SIGMOID"
      ],
      "metadata": {
        "id": "uM3NjGt4ngMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Define the architecture of the DNN\n",
        "model = Sequential([\n",
        "    Dense(128, activation='sigmoid', input_shape=(784,)),  # Input layer with 128 neurons and eLU activation\n",
        "    Dense(64, activation='relu'),                       # Hidden layer with 64 neurons and ReLU activation\n",
        "    Dense(10, activation='softmax')                     # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',   # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
        "\n",
        "# Flatten the data\n",
        "x_train_flattened = x_train.reshape(-1, 28*28)\n",
        "x_test_flattened = x_test.reshape(-1, 28*28)\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train_flattened, y_train, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test_flattened, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awlHVzdZncas",
        "outputId": "5592f919-019c-4704-be57-d659e3b002ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3613 - accuracy: 0.8994\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1631 - accuracy: 0.9520\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1110 - accuracy: 0.9665\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0828 - accuracy: 0.9746\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0635 - accuracy: 0.9797\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0854 - accuracy: 0.9742\n",
            "Test accuracy: 0.9742000102996826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DNN -LEAKY RELU\n"
      ],
      "metadata": {
        "id": "SSN9frdrnjEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Define the architecture of the DNN\n",
        "model = Sequential([\n",
        "    Dense(128, activation='LeakyReLU', input_shape=(784,)),  # Input layer with 128 neurons and eLU activation\n",
        "    Dense(64, activation='relu'),                       # Hidden layer with 64 neurons and ReLU activation\n",
        "    Dense(10, activation='softmax')                     # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',   # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
        "\n",
        "# Flatten the data\n",
        "x_train_flattened = x_train.reshape(-1, 28*28)\n",
        "x_test_flattened = x_test.reshape(-1, 28*28)\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train_flattened, y_train, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test_flattened, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdRAIBy9nmHa",
        "outputId": "23fb7048-1fa8-4585-ffcf-e3e280b79f89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2591 - accuracy: 0.9242\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1231 - accuracy: 0.9630\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0899 - accuracy: 0.9727\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0714 - accuracy: 0.9778\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0586 - accuracy: 0.9823\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0854 - accuracy: 0.9750\n",
            "Test accuracy: 0.9750000238418579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DNN-RELU/ADAMAX\n"
      ],
      "metadata": {
        "id": "E_b2K1ZWpk-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Define the architecture of the DNN\n",
        "model = Sequential([\n",
        "    Dense(128, activation='ReLU', input_shape=(784,)),  # Input layer with 128 neurons and eLU activation\n",
        "    Dense(64, activation='relu'),                       # Hidden layer with 64 neurons and ReLU activation\n",
        "    Dense(10, activation='softmax')                     # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adamax',\n",
        "              loss='sparse_categorical_crossentropy',   # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
        "\n",
        "# Flatten the data\n",
        "x_train_flattened = x_train.reshape(-1, 28*28)\n",
        "x_test_flattened = x_test.reshape(-1, 28*28)\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train_flattened, y_train, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test_flattened, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kd6s1IWphSi",
        "outputId": "48df1b28-90e9-4efd-c943-ce615c4d3f77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 0.3450 - accuracy: 0.9021\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1704 - accuracy: 0.9515\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1275 - accuracy: 0.9627\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1027 - accuracy: 0.9705\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0863 - accuracy: 0.9751\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1004 - accuracy: 0.9690\n",
            "Test accuracy: 0.968999981880188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DNN-RELU/RMSPROP"
      ],
      "metadata": {
        "id": "6lPf7O-Wpw4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Define the architecture of the DNN\n",
        "model = Sequential([\n",
        "    Dense(128, activation='ReLU', input_shape=(784,)),  # Input layer with 128 neurons and eLU activation\n",
        "    Dense(64, activation='relu'),                       # Hidden layer with 64 neurons and ReLU activation\n",
        "    Dense(10, activation='softmax')                     # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='RMSProp',\n",
        "              loss='sparse_categorical_crossentropy',   # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
        "\n",
        "# Flatten the data\n",
        "x_train_flattened = x_train.reshape(-1, 28*28)\n",
        "x_test_flattened = x_test.reshape(-1, 28*28)\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train_flattened, y_train, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test_flattened, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0UqNELgrhy4",
        "outputId": "9ee80a22-e54c-4152-b33c-fcdb91e087a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2445 - accuracy: 0.9278\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1075 - accuracy: 0.9676\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0786 - accuracy: 0.9765\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0639 - accuracy: 0.9818\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0525 - accuracy: 0.9850\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1093 - accuracy: 0.9719\n",
            "Test accuracy: 0.9718999862670898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DNN - RELU/ADAGRAD\n",
        "\n"
      ],
      "metadata": {
        "id": "y7A4uie4pokO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Define the architecture of the DNN\n",
        "model = Sequential([\n",
        "    Dense(128, activation='ReLU', input_shape=(784,)),  # Input layer with 128 neurons and eLU activation\n",
        "    Dense(64, activation='relu'),                       # Hidden layer with 64 neurons and ReLU activation\n",
        "    Dense(10, activation='softmax')                     # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adagrad',\n",
        "              loss='sparse_categorical_crossentropy',   # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
        "\n",
        "# Flatten the data\n",
        "x_train_flattened = x_train.reshape(-1, 28*28)\n",
        "x_test_flattened = x_test.reshape(-1, 28*28)\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train_flattened, y_train, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test_flattened, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CfP7fQoquaw",
        "outputId": "ad6d8567-96ca-4947-b5ab-c53df8265a15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 1.1544 - accuracy: 0.7186\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5357 - accuracy: 0.8627\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4323 - accuracy: 0.8850\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3846 - accuracy: 0.8956\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3555 - accuracy: 0.9028\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3276 - accuracy: 0.9093\n",
            "Test accuracy: 0.9093000292778015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DNN-RELU/NADAM"
      ],
      "metadata": {
        "id": "w8NLTN3Xp2MX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Define the architecture of the DNN\n",
        "model = Sequential([\n",
        "    Dense(128, activation='ReLU', input_shape=(784,)),  # Input layer with 128 neurons and eLU activation\n",
        "    Dense(64, activation='relu'),                       # Hidden layer with 64 neurons and ReLU activation\n",
        "    Dense(10, activation='softmax')                     # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='nadam',\n",
        "              loss='sparse_categorical_crossentropy',   # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
        "\n",
        "# Flatten the data\n",
        "x_train_flattened = x_train.reshape(-1, 28*28)\n",
        "x_test_flattened = x_test.reshape(-1, 28*28)\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train_flattened, y_train, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test_flattened, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJPe9XBhrNF2",
        "outputId": "9ec76c3d-d4f0-4858-8d4b-8bdfe2f9326f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2342 - accuracy: 0.9322\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1016 - accuracy: 0.9691\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0691 - accuracy: 0.9788\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0543 - accuracy: 0.9827\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0402 - accuracy: 0.9870\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0875 - accuracy: 0.9743\n",
            "Test accuracy: 0.9743000268936157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DNN - RELU /SGD"
      ],
      "metadata": {
        "id": "GsyLBq7Ap6H-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Define the architecture of the DNN\n",
        "model = Sequential([\n",
        "    Dense(128, activation='ReLU', input_shape=(784,)),  # Input layer with 128 neurons and eLU activation\n",
        "    Dense(64, activation='relu'),                       # Hidden layer with 64 neurons and ReLU activation\n",
        "    Dense(10, activation='softmax')                     # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='SGD',\n",
        "              loss='sparse_categorical_crossentropy',   # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
        "\n",
        "# Flatten the data\n",
        "x_train_flattened = x_train.reshape(-1, 28*28)\n",
        "x_test_flattened = x_test.reshape(-1, 28*28)\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train_flattened, y_train, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test_flattened, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "II7JdDK2sFbw",
        "outputId": "e5e4e1ff-1b05-4ebd-b7e7-0dfa7cfcf1ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6287 - accuracy: 0.8318\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3029 - accuracy: 0.9133\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2495 - accuracy: 0.9284\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2148 - accuracy: 0.9394\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1885 - accuracy: 0.9462\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1864 - accuracy: 0.9445\n",
            "Test accuracy: 0.9445000290870667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DNN-RELU /ADADELTA"
      ],
      "metadata": {
        "id": "xB8seo5xptbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Define the architecture of the DNN\n",
        "model = Sequential([\n",
        "    Dense(128, activation='ReLU', input_shape=(784,)),  # Input layer with 128 neurons and eLU activation\n",
        "    Dense(64, activation='relu'),                       # Hidden layer with 64 neurons and ReLU activation\n",
        "    Dense(10, activation='softmax')                     # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adadelta',\n",
        "              loss='sparse_categorical_crossentropy',   # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
        "\n",
        "# Flatten the data\n",
        "x_train_flattened = x_train.reshape(-1, 28*28)\n",
        "x_test_flattened = x_test.reshape(-1, 28*28)\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train_flattened, y_train, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test_flattened, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SmYhtGIqYwd",
        "outputId": "cbc01a4e-6397-4fb8-dd73-a463941e94ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 2.2495 - accuracy: 0.1825\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 2.1102 - accuracy: 0.3563\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.9761 - accuracy: 0.5028\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 1.8409 - accuracy: 0.5822\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 1.7067 - accuracy: 0.6332\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 1.6217 - accuracy: 0.6608\n",
            "Test accuracy: 0.6607999801635742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SGD MOMENTUM 0.9\n"
      ],
      "metadata": {
        "id": "f5FDTUl7vZwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Define the architecture of the DNN\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(784,)),  # Input layer with 128 neurons and ReLU activation\n",
        "    Dense(64, activation='relu'),                       # Hidden layer with 64 neurons and ReLU activation\n",
        "    Dense(10, activation='softmax')                     # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "\n",
        "# Compile the model with SGD optimizer and momentum\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='sparse_categorical_crossentropy',   # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
        "\n",
        "# Flatten the data\n",
        "x_train_flattened = x_train.reshape(-1, 28*28)\n",
        "x_test_flattened = x_test.reshape(-1, 28*28)\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train_flattened, y_train, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test_flattened, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcrqWsQEvb-4",
        "outputId": "dabe52ea-20be-4f9d-85ee-4af7fc10f42a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2811 - accuracy: 0.9164\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1193 - accuracy: 0.9636\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0843 - accuracy: 0.9745\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0638 - accuracy: 0.9801\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0505 - accuracy: 0.9840\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0810 - accuracy: 0.9744\n",
            "Test accuracy: 0.974399983882904\n"
          ]
        }
      ]
    }
  ]
}