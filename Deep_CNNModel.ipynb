{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPnp45Qh6MdQq09XBSXH2W6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aisyhrzi/DeepLearning/blob/main/Deep_CNNModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep Convolution **`Models`**"
      ],
      "metadata": {
        "id": "H9Af5kQbO48e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DCN - RELU /ADAM"
      ],
      "metadata": {
        "id": "sJ-ZuPtlRJy-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtp4nF7RO4Bj",
        "outputId": "99b223c1-5e2f-4874-fc46-3a7e938521fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 70s 36ms/step - loss: 0.2702 - accuracy: 0.9183\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 61s 32ms/step - loss: 0.0902 - accuracy: 0.9742\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 60s 32ms/step - loss: 0.0659 - accuracy: 0.9811\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 60s 32ms/step - loss: 0.0525 - accuracy: 0.9848\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 59s 32ms/step - loss: 0.0424 - accuracy: 0.9872\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0466 - accuracy: 0.9870\n",
            "Test accuracy: 0.9869999885559082\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Define the architecture of the deep CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),  # Convolutional layer with 32 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Conv2D(64, (3, 3), activation='relu'),                          # Convolutional layer with 64 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Conv2D(128, (3, 3), activation='relu'),                         # Convolutional layer with 128 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Flatten(),                                                       # Flatten layer to convert 2D feature maps to 1D\n",
        "    Dense(128, activation='relu'),                                   # Fully connected layer with 128 neurons and ReLU activation\n",
        "    Dropout(0.5),                                                    # Dropout layer with dropout rate 0.5 for regularization\n",
        "    Dense(10, activation='softmax')                                  # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',   # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load and preprocess the data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape and normalize the data\n",
        "x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
        "x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DCN - SOFTMAX"
      ],
      "metadata": {
        "id": "DtojdcB5S4c-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Define the architecture of the deep CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='softmax', input_shape=(28, 28, 1)),  # Convolutional layer with 32 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Conv2D(64, (3, 3), activation='relu'),                          # Convolutional layer with 64 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Conv2D(128, (3, 3), activation='relu'),                         # Convolutional layer with 128 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Flatten(),                                                       # Flatten layer to convert 2D feature maps to 1D\n",
        "    Dense(128, activation='relu'),                                   # Fully connected layer with 128 neurons and ReLU activation\n",
        "    Dropout(0.5),                                                    # Dropout layer with dropout rate 0.5 for regularization\n",
        "    Dense(10, activation='softmax')                                  # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',   # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load and preprocess the data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape and normalize the data\n",
        "x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
        "x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDusEK1IS0xV",
        "outputId": "9afea04f-eb24-43c0-e8da-77a101355069"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 70s 37ms/step - loss: 0.6408 - accuracy: 0.7834\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 69s 37ms/step - loss: 0.1783 - accuracy: 0.9471\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 71s 38ms/step - loss: 0.1320 - accuracy: 0.9614\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 64s 34ms/step - loss: 0.1065 - accuracy: 0.9688\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 64s 34ms/step - loss: 0.0898 - accuracy: 0.9730\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0716 - accuracy: 0.9785\n",
            "Test accuracy: 0.9785000085830688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DCN - PReLU"
      ],
      "metadata": {
        "id": "Vr9QJkBYS_hJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Define the architecture of the deep CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='PReLU', input_shape=(28, 28, 1)),  # Convolutional layer with 32 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Conv2D(64, (3, 3), activation='relu'),                          # Convolutional layer with 64 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Conv2D(128, (3, 3), activation='relu'),                         # Convolutional layer with 128 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Flatten(),                                                       # Flatten layer to convert 2D feature maps to 1D\n",
        "    Dense(128, activation='relu'),                                   # Fully connected layer with 128 neurons and ReLU activation\n",
        "    Dropout(0.5),                                                    # Dropout layer with dropout rate 0.5 for regularization\n",
        "    Dense(10, activation='softmax')                                  # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',   # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load and preprocess the data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape and normalize the data\n",
        "x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
        "x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ybh9JHBTCv4",
        "outputId": "c0940d67-5f32-4a1a-aa58-f03e3427fb1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 69s 36ms/step - loss: 0.2583 - accuracy: 0.9201\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 68s 36ms/step - loss: 0.0812 - accuracy: 0.9771\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 67s 36ms/step - loss: 0.0586 - accuracy: 0.9835\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 70s 37ms/step - loss: 0.0449 - accuracy: 0.9868\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 68s 36ms/step - loss: 0.0371 - accuracy: 0.9892\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0464 - accuracy: 0.9874\n",
            "Test accuracy: 0.9873999953269958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DCN - eLU"
      ],
      "metadata": {
        "id": "El7z2Ee5TGpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Define the architecture of the deep CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='ELU', input_shape=(28, 28, 1)),  # Convolutional layer with 32 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Conv2D(64, (3, 3), activation='relu'),                          # Convolutional layer with 64 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Conv2D(128, (3, 3), activation='relu'),                         # Convolutional layer with 128 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Flatten(),                                                       # Flatten layer to convert 2D feature maps to 1D\n",
        "    Dense(128, activation='relu'),                                   # Fully connected layer with 128 neurons and ReLU activation\n",
        "    Dropout(0.5),                                                    # Dropout layer with dropout rate 0.5 for regularization\n",
        "    Dense(10, activation='softmax')                                  # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',   # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load and preprocess the data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape and normalize the data\n",
        "x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
        "x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4O62F5nTJze",
        "outputId": "f02d2576-9641-43a2-d608-bca6c55c9228"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 62s 32ms/step - loss: 0.2640 - accuracy: 0.9196\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 59s 32ms/step - loss: 0.0925 - accuracy: 0.9738\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 60s 32ms/step - loss: 0.0681 - accuracy: 0.9806\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 60s 32ms/step - loss: 0.0540 - accuracy: 0.9847\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 59s 32ms/step - loss: 0.0435 - accuracy: 0.9868\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0445 - accuracy: 0.9884\n",
            "Test accuracy: 0.9883999824523926\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DCN - Sigmoid"
      ],
      "metadata": {
        "id": "Lq3oNujITMlv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Define the architecture of the deep CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='sigmoid', input_shape=(28, 28, 1)),  # Convolutional layer with 32 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Conv2D(64, (3, 3), activation='relu'),                          # Convolutional layer with 64 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Conv2D(128, (3, 3), activation='relu'),                         # Convolutional layer with 128 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Flatten(),                                                       # Flatten layer to convert 2D feature maps to 1D\n",
        "    Dense(128, activation='relu'),                                   # Fully connected layer with 128 neurons and ReLU activation\n",
        "    Dropout(0.5),                                                    # Dropout layer with dropout rate 0.5 for regularization\n",
        "    Dense(10, activation='softmax')                                  # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',   # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load and preprocess the data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape and normalize the data\n",
        "x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
        "x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7BpopDbTShv",
        "outputId": "c878989e-b818-4f27-a32c-dd8716a48774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 60s 32ms/step - loss: 2.3019 - accuracy: 0.1115\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 58s 31ms/step - loss: 2.3014 - accuracy: 0.1119\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 59s 32ms/step - loss: 2.3014 - accuracy: 0.1124\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 62s 33ms/step - loss: 2.3013 - accuracy: 0.1124\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 58s 31ms/step - loss: 2.3013 - accuracy: 0.1124\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 2.3010 - accuracy: 0.1135\n",
            "Test accuracy: 0.11349999904632568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DCN - tanh"
      ],
      "metadata": {
        "id": "40dW3AATTUyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Define the architecture of the deep CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='tanh', input_shape=(28, 28, 1)),  # Convolutional layer with 32 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Conv2D(64, (3, 3), activation='relu'),                          # Convolutional layer with 64 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Conv2D(128, (3, 3), activation='relu'),                         # Convolutional layer with 128 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Flatten(),                                                       # Flatten layer to convert 2D feature maps to 1D\n",
        "    Dense(128, activation='relu'),                                   # Fully connected layer with 128 neurons and ReLU activation\n",
        "    Dropout(0.5),                                                    # Dropout layer with dropout rate 0.5 for regularization\n",
        "    Dense(10, activation='softmax')                                  # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',   # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load and preprocess the data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape and normalize the data\n",
        "x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
        "x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gghfpPBaTYWC",
        "outputId": "49647f87-f8db-45d5-8a91-f2f234235e95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 60s 31ms/step - loss: 0.2635 - accuracy: 0.9184\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 59s 31ms/step - loss: 0.0921 - accuracy: 0.9734\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 57s 31ms/step - loss: 0.0686 - accuracy: 0.9801\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 60s 32ms/step - loss: 0.0555 - accuracy: 0.9840\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 58s 31ms/step - loss: 0.0469 - accuracy: 0.9862\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.0536 - accuracy: 0.9841\n",
            "Test accuracy: 0.9840999841690063\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DCN - LEAKYReLU"
      ],
      "metadata": {
        "id": "w8k-9YdiTaD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Define the architecture of the deep CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='LeakyReLU', input_shape=(28, 28, 1)),  # Convolutional layer with 32 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Conv2D(64, (3, 3), activation='relu'),                          # Convolutional layer with 64 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Conv2D(128, (3, 3), activation='relu'),                         # Convolutional layer with 128 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Flatten(),                                                       # Flatten layer to convert 2D feature maps to 1D\n",
        "    Dense(128, activation='relu'),                                   # Fully connected layer with 128 neurons and ReLU activation\n",
        "    Dropout(0.5),                                                    # Dropout layer with dropout rate 0.5 for regularization\n",
        "    Dense(10, activation='softmax')                                  # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',   # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load and preprocess the data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape and normalize the data\n",
        "x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
        "x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2jjOLZfTevs",
        "outputId": "37456e44-5360-4b69-9963-69153fdc5100"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 58s 31ms/step - loss: 0.2676 - accuracy: 0.9183\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 60s 32ms/step - loss: 0.0893 - accuracy: 0.9748\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 57s 31ms/step - loss: 0.0655 - accuracy: 0.9811\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 58s 31ms/step - loss: 0.0530 - accuracy: 0.9851\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 57s 30ms/step - loss: 0.0432 - accuracy: 0.9869\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0560 - accuracy: 0.9860\n",
            "Test accuracy: 0.9860000014305115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DCN - ELU +ADAMAX"
      ],
      "metadata": {
        "id": "qE9FU_D1l31b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Define the architecture of the deep CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='ELU', input_shape=(28, 28, 1)),  # Convolutional layer with 32 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Conv2D(64, (3, 3), activation='relu'),                          # Convolutional layer with 64 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Conv2D(128, (3, 3), activation='relu'),                         # Convolutional layer with 128 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Flatten(),                                                       # Flatten layer to convert 2D feature maps to 1D\n",
        "    Dense(128, activation='relu'),                                   # Fully connected layer with 128 neurons and ReLU activation\n",
        "    Dropout(0.5),                                                    # Dropout layer with dropout rate 0.5 for regularization\n",
        "    Dense(10, activation='softmax')                                  # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adamax',\n",
        "              loss='sparse_categorical_crossentropy',   # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load and preprocess the data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape and normalize the data\n",
        "x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
        "x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyY9Xwbtl6dO",
        "outputId": "ed623b01-97fd-4972-afe6-a41f62a5ef17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 64s 34ms/step - loss: 0.4139 - accuracy: 0.8730\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 59s 31ms/step - loss: 0.1558 - accuracy: 0.9542\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 60s 32ms/step - loss: 0.1158 - accuracy: 0.9665\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 59s 32ms/step - loss: 0.0940 - accuracy: 0.9727\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 59s 31ms/step - loss: 0.0790 - accuracy: 0.9770\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.0562 - accuracy: 0.9829\n",
            "Test accuracy: 0.9829000234603882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CDN - ELU +SGD"
      ],
      "metadata": {
        "id": "LVBfhyMTmYeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Define the architecture of the deep CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='ELU', input_shape=(28, 28, 1)),  # Convolutional layer with 32 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Conv2D(64, (3, 3), activation='relu'),                          # Convolutional layer with 64 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Conv2D(128, (3, 3), activation='relu'),                         # Convolutional layer with 128 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Flatten(),                                                       # Flatten layer to convert 2D feature maps to 1D\n",
        "    Dense(128, activation='relu'),                                   # Fully connected layer with 128 neurons and ReLU activation\n",
        "    Dropout(0.5),                                                    # Dropout layer with dropout rate 0.5 for regularization\n",
        "    Dense(10, activation='softmax')                                  # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='SGD',\n",
        "              loss='sparse_categorical_crossentropy',   # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load and preprocess the data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape and normalize the data\n",
        "x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
        "x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fLF7A1bmcff",
        "outputId": "8ad64576-d58e-4b72-818c-7e8b96f05eb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 63s 33ms/step - loss: 0.9753 - accuracy: 0.6863\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 61s 33ms/step - loss: 0.2644 - accuracy: 0.9205\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 60s 32ms/step - loss: 0.1859 - accuracy: 0.9453\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 59s 31ms/step - loss: 0.1513 - accuracy: 0.9549\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 60s 32ms/step - loss: 0.1290 - accuracy: 0.9624\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0803 - accuracy: 0.9754\n",
            "Test accuracy: 0.9753999710083008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dcn - ADAGRAD"
      ],
      "metadata": {
        "id": "M61OlnO9n1AK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Define the architecture of the deep CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='ELU', input_shape=(28, 28, 1)),  # Convolutional layer with 32 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Conv2D(64, (3, 3), activation='relu'),                          # Convolutional layer with 64 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Conv2D(128, (3, 3), activation='relu'),                         # Convolutional layer with 128 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Flatten(),                                                       # Flatten layer to convert 2D feature maps to 1D\n",
        "    Dense(128, activation='relu'),                                   # Fully connected layer with 128 neurons and ReLU activation\n",
        "    Dropout(0.5),                                                    # Dropout layer with dropout rate 0.5 for regularization\n",
        "    Dense(10, activation='softmax')                                  # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='ADAGRAD',\n",
        "              loss='sparse_categorical_crossentropy',   # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load and preprocess the data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape and normalize the data\n",
        "x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
        "x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFOE1dLTn3Xe",
        "outputId": "c2893e43-8ee5-4982-8aae-487f8dbc1baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 63s 33ms/step - loss: 1.9821 - accuracy: 0.3690\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 60s 32ms/step - loss: 0.8813 - accuracy: 0.7388\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 58s 31ms/step - loss: 0.5510 - accuracy: 0.8374\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 60s 32ms/step - loss: 0.4404 - accuracy: 0.8723\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 59s 31ms/step - loss: 0.3804 - accuracy: 0.8891\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2352 - accuracy: 0.9295\n",
            "Test accuracy: 0.9294999837875366\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DNN- SGD MOMENTUM"
      ],
      "metadata": {
        "id": "tzLnejWzphpx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Define the architecture of the deep CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='ELU', input_shape=(28, 28, 1)),  # Convolutional layer with 32 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Conv2D(64, (3, 3), activation='relu'),                          # Convolutional layer with 64 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Conv2D(128, (3, 3), activation='relu'),                         # Convolutional layer with 128 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Flatten(),                                                       # Flatten layer to convert 2D feature maps to 1D\n",
        "    Dense(128, activation='relu'),                                   # Fully connected layer with 128 neurons and ReLU activation\n",
        "    Dropout(0.5),                                                    # Dropout layer with dropout rate 0.5 for regularization\n",
        "    Dense(10, activation='softmax')                                  # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
        "\n",
        "model.compile(optimizer= optimizer,\n",
        "              loss='sparse_categorical_crossentropy',   # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load and preprocess the data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape and normalize the data\n",
        "x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
        "x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hdQxoe7plZO",
        "outputId": "0d8113d2-4367-4fe4-dc71-f5a64c849bc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 62s 33ms/step - loss: 0.3355 - accuracy: 0.8958\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 62s 33ms/step - loss: 0.1022 - accuracy: 0.9703\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 62s 33ms/step - loss: 0.0722 - accuracy: 0.9787\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 60s 32ms/step - loss: 0.0575 - accuracy: 0.9827\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 61s 33ms/step - loss: 0.0504 - accuracy: 0.9849\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0512 - accuracy: 0.9860\n",
            "Test accuracy: 0.9860000014305115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DCN - RMSProp"
      ],
      "metadata": {
        "id": "X6MhGzBexLPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Define the architecture of the deep CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='ELU', input_shape=(28, 28, 1)),  # Convolutional layer with 32 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Conv2D(64, (3, 3), activation='relu'),                          # Convolutional layer with 64 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Conv2D(128, (3, 3), activation='relu'),                         # Convolutional layer with 128 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Flatten(),                                                       # Flatten layer to convert 2D feature maps to 1D\n",
        "    Dense(128, activation='relu'),                                   # Fully connected layer with 128 neurons and ReLU activation\n",
        "    Dropout(0.5),                                                    # Dropout layer with dropout rate 0.5 for regularization\n",
        "    Dense(10, activation='softmax')                                  # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='RMSProp',\n",
        "              loss='sparse_categorical_crossentropy',   # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load and preprocess the data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape and normalize the data\n",
        "x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
        "x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_FklA2pxUp5",
        "outputId": "589d818d-0972-4830-eeb9-ac1fcfb1b222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 60s 32ms/step - loss: 0.2540 - accuracy: 0.9232\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 60s 32ms/step - loss: 0.0899 - accuracy: 0.9754\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 60s 32ms/step - loss: 0.0725 - accuracy: 0.9799\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 59s 31ms/step - loss: 0.0639 - accuracy: 0.9832\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 61s 33ms/step - loss: 0.0661 - accuracy: 0.9833\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0646 - accuracy: 0.9836\n",
            "Test accuracy: 0.9836000204086304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DNS - NADAM"
      ],
      "metadata": {
        "id": "RT21AvRMxkJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Define the architecture of the deep CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='ELU', input_shape=(28, 28, 1)),  # Convolutional layer with 32 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Conv2D(64, (3, 3), activation='relu'),                          # Convolutional layer with 64 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Conv2D(128, (3, 3), activation='relu'),                         # Convolutional layer with 128 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Flatten(),                                                       # Flatten layer to convert 2D feature maps to 1D\n",
        "    Dense(128, activation='relu'),                                   # Fully connected layer with 128 neurons and ReLU activation\n",
        "    Dropout(0.5),                                                    # Dropout layer with dropout rate 0.5 for regularization\n",
        "    Dense(10, activation='softmax')                                  # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='NADAM',\n",
        "              loss='sparse_categorical_crossentropy',   # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load and preprocess the data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape and normalize the data\n",
        "x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
        "x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dWuT1hbxxZV",
        "outputId": "d4b5b37f-e5c9-41fe-bafc-3c384cbcb8d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 66s 34ms/step - loss: 0.2514 - accuracy: 0.9236\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 62s 33ms/step - loss: 0.0925 - accuracy: 0.9732\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 60s 32ms/step - loss: 0.0685 - accuracy: 0.9801\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 63s 33ms/step - loss: 0.0539 - accuracy: 0.9844\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 61s 33ms/step - loss: 0.0447 - accuracy: 0.9870\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0518 - accuracy: 0.9856\n",
            "Test accuracy: 0.9855999946594238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DNS -ADADELTA"
      ],
      "metadata": {
        "id": "G_lC7KbAxzwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Define the architecture of the deep CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='ELU', input_shape=(28, 28, 1)),  # Convolutional layer with 32 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Conv2D(64, (3, 3), activation='relu'),                          # Convolutional layer with 64 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Conv2D(128, (3, 3), activation='relu'),                         # Convolutional layer with 128 filters of size 3x3 and ReLU activation\n",
        "    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n",
        "    Flatten(),                                                       # Flatten layer to convert 2D feature maps to 1D\n",
        "    Dense(128, activation='relu'),                                   # Fully connected layer with 128 neurons and ReLU activation\n",
        "    Dropout(0.5),                                                    # Dropout layer with dropout rate 0.5 for regularization\n",
        "    Dense(10, activation='softmax')                                  # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='NADAM',\n",
        "              loss='sparse_categorical_crossentropy',   # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load and preprocess the data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape and normalize the data\n",
        "x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
        "x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7qTO9zI0BJf",
        "outputId": "2236e936-ab5c-4160-cf9b-87d9574116d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 64s 33ms/step - loss: 0.2561 - accuracy: 0.9218\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 61s 33ms/step - loss: 0.0938 - accuracy: 0.9736\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 62s 33ms/step - loss: 0.0689 - accuracy: 0.9796\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 63s 34ms/step - loss: 0.0549 - accuracy: 0.9840\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 61s 33ms/step - loss: 0.0455 - accuracy: 0.9865\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0488 - accuracy: 0.9862\n",
            "Test accuracy: 0.9861999750137329\n"
          ]
        }
      ]
    }
  ]
}